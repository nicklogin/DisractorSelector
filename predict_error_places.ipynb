{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "zfile = ZipFile(\"processed_texts.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19984\\3040792838.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for file in tqdm_notebook(zfile.filelist, total=len(zfile.filelist)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe960f732b842afbe82bf854cb0798f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_texts = []\n",
    "\n",
    "for file in tqdm_notebook(zfile.filelist, total=len(zfile.filelist)):\n",
    "    if file.filename.endswith(\".txt\"):\n",
    "        with zfile.open(\n",
    "            file.filename\n",
    "        ) as inp:\n",
    "            text = inp.read()\n",
    "        with zfile.open(\n",
    "            file.filename.replace(\".txt\",\".json\")\n",
    "        ) as inp:\n",
    "            meta = json.load(inp)\n",
    "        processed_texts.append((file.filename, text, meta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем среднюю длину (с 95% доверительным интервалом) предложения в processed_texts и среднее количество ошибок на предложение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19984\\295802365.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  sent for file, text, meta in tqdm_notebook(processed_texts)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9539e75c7a14d77ac5ff9910c208cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19079 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_sents = [\n",
    "    sent for file, text, meta in tqdm_notebook(processed_texts)\n",
    "    for sent in sent_tokenize(text.decode('utf8'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_lens = [len(sent) for sent in processed_sents]\n",
    "processed_err_counts = [sent.count(\"<<\") for sent in processed_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>231029.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>165.681066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>92.759507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1119.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count  231029.000000\n",
       "mean      165.681066\n",
       "std        92.759507\n",
       "min         1.000000\n",
       "25%       100.000000\n",
       "50%       148.000000\n",
       "75%       211.000000\n",
       "max      1119.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(processed_lens).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ielts</th>\n",
       "      <th>CEFR_level</th>\n",
       "      <th>task_id</th>\n",
       "      <th>ann_checked</th>\n",
       "      <th>work_type</th>\n",
       "      <th>filename</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>O18</td>\n",
       "      <td>0</td>\n",
       "      <td>exam</td>\n",
       "      <td>2020_MLa_2297_2</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>O18</td>\n",
       "      <td>0</td>\n",
       "      <td>exam</td>\n",
       "      <td>2020_MLa_2744_2</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>TRUE</td>\n",
       "      <td></td>\n",
       "      <td>G15</td>\n",
       "      <td>0</td>\n",
       "      <td>exam</td>\n",
       "      <td>2020_MLa_3271_1</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>C1</td>\n",
       "      <td>O19</td>\n",
       "      <td>0</td>\n",
       "      <td>exam</td>\n",
       "      <td>2017_EGe_12_2</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>TRUE</td>\n",
       "      <td></td>\n",
       "      <td>O30</td>\n",
       "      <td>0</td>\n",
       "      <td>exam</td>\n",
       "      <td>2020_MLa_5066_2</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19074</th>\n",
       "      <td>None</td>\n",
       "      <td>TRUE</td>\n",
       "      <td></td>\n",
       "      <td>G27</td>\n",
       "      <td>0</td>\n",
       "      <td>exam</td>\n",
       "      <td>2020_MLa_5087_1</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19075</th>\n",
       "      <td>None</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>C1</td>\n",
       "      <td>G27</td>\n",
       "      <td>0</td>\n",
       "      <td>exam</td>\n",
       "      <td>2019_ABu_147_1</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19076</th>\n",
       "      <td>None</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>None</td>\n",
       "      <td>G20</td>\n",
       "      <td>0</td>\n",
       "      <td>exam</td>\n",
       "      <td>2020_MLa_2224_1</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19077</th>\n",
       "      <td>None</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>B1+</td>\n",
       "      <td>G14</td>\n",
       "      <td>0</td>\n",
       "      <td>exam</td>\n",
       "      <td>2016_EKu_166_1</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19078</th>\n",
       "      <td>None</td>\n",
       "      <td>TRUE</td>\n",
       "      <td></td>\n",
       "      <td>G28</td>\n",
       "      <td>0</td>\n",
       "      <td>exam</td>\n",
       "      <td>2020_MLa_4047_1</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19079 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_type ielts CEFR_level task_id ann_checked work_type  \\\n",
       "0          None  TRUE       None     O18           0      exam   \n",
       "1          None  TRUE       None     O18           0      exam   \n",
       "2          None  TRUE                G15           0      exam   \n",
       "3          None  TRUE         C1     O19           0      exam   \n",
       "4          None  TRUE                O30           0      exam   \n",
       "...         ...   ...        ...     ...         ...       ...   \n",
       "19074      None  TRUE                G27           0      exam   \n",
       "19075      None  TRUE         C1     G27           0      exam   \n",
       "19076      None  TRUE       None     G20           0      exam   \n",
       "19077      None  TRUE        B1+     G14           0      exam   \n",
       "19078      None  TRUE                G28           0      exam   \n",
       "\n",
       "              filename                                             folder  \n",
       "0      2020_MLa_2297_2  downloaded_2022_05_03_13_27_13286380/exam/Exam...  \n",
       "1      2020_MLa_2744_2  downloaded_2022_05_03_13_27_13286380/exam/Exam...  \n",
       "2      2020_MLa_3271_1  downloaded_2022_05_03_13_27_13286380/exam/Exam...  \n",
       "3        2017_EGe_12_2  downloaded_2022_05_03_13_27_13286380/exam/Old_...  \n",
       "4      2020_MLa_5066_2  downloaded_2022_05_03_13_27_13286380/exam/Exam...  \n",
       "...                ...                                                ...  \n",
       "19074  2020_MLa_5087_1  downloaded_2022_05_03_13_27_13286380/exam/Exam...  \n",
       "19075   2019_ABu_147_1  downloaded_2022_05_03_13_27_13286380/exam/Exam...  \n",
       "19076  2020_MLa_2224_1  downloaded_2022_05_03_13_27_13286380/exam/Exam...  \n",
       "19077   2016_EKu_166_1  downloaded_2022_05_03_13_27_13286380/exam/Old_...  \n",
       "19078  2020_MLa_4047_1  downloaded_2022_05_03_13_27_13286380/exam/Exam...  \n",
       "\n",
       "[19079 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.DataFrame(\n",
    "    [meta for name, text, meta in processed_texts]\n",
    ")\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       8443\n",
       "B1+    1875\n",
       "B2+    1010\n",
       "B1      652\n",
       "C1      501\n",
       "B2      465\n",
       "C1+     156\n",
       "B1-     138\n",
       "A2       11\n",
       "Name: CEFR_level, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[\"CEFR_level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G20    1186\n",
       "O18    1133\n",
       "G13    1056\n",
       "G24    1031\n",
       "O16     988\n",
       "       ... \n",
       "G01      21\n",
       "O08      20\n",
       "G09      15\n",
       "G23      13\n",
       "0         2\n",
       "Name: task_id, Length: 62, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[\"task_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12678\n",
       "0     5993\n",
       "1      196\n",
       "Name: ann_checked, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[\"ann_checked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(re.finditer(\n",
    "    \"#DELETE#([0-9]+)#\",\n",
    "    processed_texts[0][1].decode('utf-8')\n",
    "))[0].span()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module re:\n",
      "\n",
      "NAME\n",
      "    re - Support for regular expressions (RE).\n",
      "\n",
      "MODULE REFERENCE\n",
      "    https://docs.python.org/3.8/library/re\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    This module provides regular expression matching operations similar to\n",
      "    those found in Perl.  It supports both 8-bit and Unicode strings; both\n",
      "    the pattern and the strings being processed can contain null bytes and\n",
      "    characters outside the US ASCII range.\n",
      "    \n",
      "    Regular expressions can contain both special and ordinary characters.\n",
      "    Most ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\n",
      "    regular expressions; they simply match themselves.  You can\n",
      "    concatenate ordinary characters, so last matches the string 'last'.\n",
      "    \n",
      "    The special characters are:\n",
      "        \".\"      Matches any character except a newline.\n",
      "        \"^\"      Matches the start of the string.\n",
      "        \"$\"      Matches the end of the string or just before the newline at\n",
      "                 the end of the string.\n",
      "        \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n",
      "                 Greedy means that it will match as many repetitions as possible.\n",
      "        \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n",
      "        \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n",
      "        *?,+?,?? Non-greedy versions of the previous three special characters.\n",
      "        {m,n}    Matches from m to n repetitions of the preceding RE.\n",
      "        {m,n}?   Non-greedy version of the above.\n",
      "        \"\\\\\"     Either escapes special characters or signals a special sequence.\n",
      "        []       Indicates a set of characters.\n",
      "                 A \"^\" as the first character indicates a complementing set.\n",
      "        \"|\"      A|B, creates an RE that will match either A or B.\n",
      "        (...)    Matches the RE inside the parentheses.\n",
      "                 The contents can be retrieved or matched later in the string.\n",
      "        (?aiLmsux) The letters set the corresponding flags defined below.\n",
      "        (?:...)  Non-grouping version of regular parentheses.\n",
      "        (?P<name>...) The substring matched by the group is accessible by name.\n",
      "        (?P=name)     Matches the text matched earlier by the group named name.\n",
      "        (?#...)  A comment; ignored.\n",
      "        (?=...)  Matches if ... matches next, but doesn't consume the string.\n",
      "        (?!...)  Matches if ... doesn't match next.\n",
      "        (?<=...) Matches if preceded by ... (must be fixed length).\n",
      "        (?<!...) Matches if not preceded by ... (must be fixed length).\n",
      "        (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,\n",
      "                           the (optional) no pattern otherwise.\n",
      "    \n",
      "    The special sequences consist of \"\\\\\" and a character from the list\n",
      "    below.  If the ordinary character is not on the list, then the\n",
      "    resulting RE will match the second character.\n",
      "        \\number  Matches the contents of the group of the same number.\n",
      "        \\A       Matches only at the start of the string.\n",
      "        \\Z       Matches only at the end of the string.\n",
      "        \\b       Matches the empty string, but only at the start or end of a word.\n",
      "        \\B       Matches the empty string, but not at the start or end of a word.\n",
      "        \\d       Matches any decimal digit; equivalent to the set [0-9] in\n",
      "                 bytes patterns or string patterns with the ASCII flag.\n",
      "                 In string patterns without the ASCII flag, it will match the whole\n",
      "                 range of Unicode digits.\n",
      "        \\D       Matches any non-digit character; equivalent to [^\\d].\n",
      "        \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] in\n",
      "                 bytes patterns or string patterns with the ASCII flag.\n",
      "                 In string patterns without the ASCII flag, it will match the whole\n",
      "                 range of Unicode whitespace characters.\n",
      "        \\S       Matches any non-whitespace character; equivalent to [^\\s].\n",
      "        \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]\n",
      "                 in bytes patterns or string patterns with the ASCII flag.\n",
      "                 In string patterns without the ASCII flag, it will match the\n",
      "                 range of Unicode alphanumeric characters (letters plus digits\n",
      "                 plus underscore).\n",
      "                 With LOCALE, it will match the set [0-9_] plus characters defined\n",
      "                 as letters for the current locale.\n",
      "        \\W       Matches the complement of \\w.\n",
      "        \\\\       Matches a literal backslash.\n",
      "    \n",
      "    This module exports the following functions:\n",
      "        match     Match a regular expression pattern to the beginning of a string.\n",
      "        fullmatch Match a regular expression pattern to all of a string.\n",
      "        search    Search a string for the presence of a pattern.\n",
      "        sub       Substitute occurrences of a pattern found in a string.\n",
      "        subn      Same as sub, but also return the number of substitutions made.\n",
      "        split     Split a string by the occurrences of a pattern.\n",
      "        findall   Find all occurrences of a pattern in a string.\n",
      "        finditer  Return an iterator yielding a Match object for each match.\n",
      "        compile   Compile a pattern into a Pattern object.\n",
      "        purge     Clear the regular expression cache.\n",
      "        escape    Backslash all non-alphanumerics in a string.\n",
      "    \n",
      "    Each function other than purge and escape can take an optional 'flags' argument\n",
      "    consisting of one or more of the following module constants, joined by \"|\".\n",
      "    A, L, and U are mutually exclusive.\n",
      "        A  ASCII       For string patterns, make \\w, \\W, \\b, \\B, \\d, \\D\n",
      "                       match the corresponding ASCII character categories\n",
      "                       (rather than the whole Unicode categories, which is the\n",
      "                       default).\n",
      "                       For bytes patterns, this flag is the only available\n",
      "                       behaviour and needn't be specified.\n",
      "        I  IGNORECASE  Perform case-insensitive matching.\n",
      "        L  LOCALE      Make \\w, \\W, \\b, \\B, dependent on the current locale.\n",
      "        M  MULTILINE   \"^\" matches the beginning of lines (after a newline)\n",
      "                       as well as the string.\n",
      "                       \"$\" matches the end of lines (before a newline) as well\n",
      "                       as the end of the string.\n",
      "        S  DOTALL      \".\" matches any character at all, including the newline.\n",
      "        X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.\n",
      "        U  UNICODE     For compatibility only. Ignored for string patterns (it\n",
      "                       is the default), and forbidden for bytes patterns.\n",
      "    \n",
      "    This module also defines an exception 'error'.\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        error\n",
      "    builtins.object\n",
      "        Match\n",
      "        Pattern\n",
      "    \n",
      "    class Match(builtins.object)\n",
      "     |  The result of re.match() and re.search().\n",
      "     |  Match objects always have a boolean value of True.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __copy__(self, /)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo, /)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  end(self, group=0, /)\n",
      "     |      Return index of the end of the substring matched by group.\n",
      "     |  \n",
      "     |  expand(self, /, template)\n",
      "     |      Return the string obtained by doing backslash substitution on the string template, as done by the sub() method.\n",
      "     |  \n",
      "     |  group(...)\n",
      "     |      group([group1, ...]) -> str or tuple.\n",
      "     |      Return subgroup(s) of the match by indices or names.\n",
      "     |      For 0 returns the entire match.\n",
      "     |  \n",
      "     |  groupdict(self, /, default=None)\n",
      "     |      Return a dictionary containing all the named subgroups of the match, keyed by the subgroup name.\n",
      "     |      \n",
      "     |      default\n",
      "     |        Is used for groups that did not participate in the match.\n",
      "     |  \n",
      "     |  groups(self, /, default=None)\n",
      "     |      Return a tuple containing all the subgroups of the match, from 1.\n",
      "     |      \n",
      "     |      default\n",
      "     |        Is used for groups that did not participate in the match.\n",
      "     |  \n",
      "     |  span(self, group=0, /)\n",
      "     |      For match object m, return the 2-tuple (m.start(group), m.end(group)).\n",
      "     |  \n",
      "     |  start(self, group=0, /)\n",
      "     |      Return index of the start of the substring matched by group.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  endpos\n",
      "     |      The index into the string beyond which the RE engine will not go.\n",
      "     |  \n",
      "     |  lastgroup\n",
      "     |      The name of the last matched capturing group.\n",
      "     |  \n",
      "     |  lastindex\n",
      "     |      The integer index of the last matched capturing group.\n",
      "     |  \n",
      "     |  pos\n",
      "     |      The index into the string at which the RE engine started looking for a match.\n",
      "     |  \n",
      "     |  re\n",
      "     |      The regular expression object.\n",
      "     |  \n",
      "     |  regs\n",
      "     |  \n",
      "     |  string\n",
      "     |      The string passed to match() or search().\n",
      "    \n",
      "    class Pattern(builtins.object)\n",
      "     |  Compiled regular expression object.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __copy__(self, /)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo, /)\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  findall(self, /, string, pos=0, endpos=9223372036854775807)\n",
      "     |      Return a list of all non-overlapping matches of pattern in string.\n",
      "     |  \n",
      "     |  finditer(self, /, string, pos=0, endpos=9223372036854775807)\n",
      "     |      Return an iterator over all non-overlapping matches for the RE pattern in string.\n",
      "     |      \n",
      "     |      For each match, the iterator returns a match object.\n",
      "     |  \n",
      "     |  fullmatch(self, /, string, pos=0, endpos=9223372036854775807)\n",
      "     |      Matches against all of the string.\n",
      "     |  \n",
      "     |  match(self, /, string, pos=0, endpos=9223372036854775807)\n",
      "     |      Matches zero or more characters at the beginning of the string.\n",
      "     |  \n",
      "     |  scanner(self, /, string, pos=0, endpos=9223372036854775807)\n",
      "     |  \n",
      "     |  search(self, /, string, pos=0, endpos=9223372036854775807)\n",
      "     |      Scan through string looking for a match, and return a corresponding match object instance.\n",
      "     |      \n",
      "     |      Return None if no position in the string matches.\n",
      "     |  \n",
      "     |  split(self, /, string, maxsplit=0)\n",
      "     |      Split string by the occurrences of pattern.\n",
      "     |  \n",
      "     |  sub(self, /, repl, string, count=0)\n",
      "     |      Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl.\n",
      "     |  \n",
      "     |  subn(self, /, repl, string, count=0)\n",
      "     |      Return the tuple (new_string, number_of_subs_made) found by replacing the leftmost non-overlapping occurrences of pattern with the replacement repl.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  flags\n",
      "     |      The regex matching flags.\n",
      "     |  \n",
      "     |  groupindex\n",
      "     |      A dictionary mapping group names to group numbers.\n",
      "     |  \n",
      "     |  groups\n",
      "     |      The number of capturing groups in the pattern.\n",
      "     |  \n",
      "     |  pattern\n",
      "     |      The pattern string from which the RE object was compiled.\n",
      "    \n",
      "    class error(builtins.Exception)\n",
      "     |  error(msg, pattern=None, pos=None)\n",
      "     |  \n",
      "     |  Exception raised for invalid regular expressions.\n",
      "     |  \n",
      "     |  Attributes:\n",
      "     |  \n",
      "     |      msg: The unformatted error message\n",
      "     |      pattern: The regular expression pattern\n",
      "     |      pos: The index in the pattern where compilation failed (may be None)\n",
      "     |      lineno: The line corresponding to pos (may be None)\n",
      "     |      colno: The column corresponding to pos (may be None)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      error\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, msg, pattern=None, pos=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    compile(pattern, flags=0)\n",
      "        Compile a regular expression pattern, returning a Pattern object.\n",
      "    \n",
      "    escape(pattern)\n",
      "        Escape special characters in a string.\n",
      "    \n",
      "    findall(pattern, string, flags=0)\n",
      "        Return a list of all non-overlapping matches in the string.\n",
      "        \n",
      "        If one or more capturing groups are present in the pattern, return\n",
      "        a list of groups; this will be a list of tuples if the pattern\n",
      "        has more than one group.\n",
      "        \n",
      "        Empty matches are included in the result.\n",
      "    \n",
      "    finditer(pattern, string, flags=0)\n",
      "        Return an iterator over all non-overlapping matches in the\n",
      "        string.  For each match, the iterator returns a Match object.\n",
      "        \n",
      "        Empty matches are included in the result.\n",
      "    \n",
      "    fullmatch(pattern, string, flags=0)\n",
      "        Try to apply the pattern to all of the string, returning\n",
      "        a Match object, or None if no match was found.\n",
      "    \n",
      "    match(pattern, string, flags=0)\n",
      "        Try to apply the pattern at the start of the string, returning\n",
      "        a Match object, or None if no match was found.\n",
      "    \n",
      "    purge()\n",
      "        Clear the regular expression caches\n",
      "    \n",
      "    search(pattern, string, flags=0)\n",
      "        Scan through string looking for a match to the pattern, returning\n",
      "        a Match object, or None if no match was found.\n",
      "    \n",
      "    split(pattern, string, maxsplit=0, flags=0)\n",
      "        Split the source string by the occurrences of the pattern,\n",
      "        returning a list containing the resulting substrings.  If\n",
      "        capturing parentheses are used in pattern, then the text of all\n",
      "        groups in the pattern are also returned as part of the resulting\n",
      "        list.  If maxsplit is nonzero, at most maxsplit splits occur,\n",
      "        and the remainder of the string is returned as the final element\n",
      "        of the list.\n",
      "    \n",
      "    sub(pattern, repl, string, count=0, flags=0)\n",
      "        Return the string obtained by replacing the leftmost\n",
      "        non-overlapping occurrences of the pattern in string by the\n",
      "        replacement repl.  repl can be either a string or a callable;\n",
      "        if a string, backslash escapes in it are processed.  If it is\n",
      "        a callable, it's passed the Match object and must return\n",
      "        a replacement string to be used.\n",
      "    \n",
      "    subn(pattern, repl, string, count=0, flags=0)\n",
      "        Return a 2-tuple containing (new_string, number).\n",
      "        new_string is the string obtained by replacing the leftmost\n",
      "        non-overlapping occurrences of the pattern in the source\n",
      "        string by the replacement repl.  number is the number of\n",
      "        substitutions that were made. repl can be either a string or a\n",
      "        callable; if a string, backslash escapes in it are processed.\n",
      "        If it is a callable, it's passed the Match object and must\n",
      "        return a replacement string to be used.\n",
      "    \n",
      "    template(pattern, flags=0)\n",
      "        Compile a template pattern, returning a Pattern object\n",
      "\n",
      "DATA\n",
      "    A = re.ASCII\n",
      "    ASCII = re.ASCII\n",
      "    DOTALL = re.DOTALL\n",
      "    I = re.IGNORECASE\n",
      "    IGNORECASE = re.IGNORECASE\n",
      "    L = re.LOCALE\n",
      "    LOCALE = re.LOCALE\n",
      "    M = re.MULTILINE\n",
      "    MULTILINE = re.MULTILINE\n",
      "    S = re.DOTALL\n",
      "    U = re.UNICODE\n",
      "    UNICODE = re.UNICODE\n",
      "    VERBOSE = re.VERBOSE\n",
      "    X = re.VERBOSE\n",
      "    __all__ = ['match', 'fullmatch', 'search', 'sub', 'subn', 'split', 'fi...\n",
      "\n",
      "VERSION\n",
      "    2.2.1\n",
      "\n",
      "FILE\n",
      "    c:\\program files\\python38\\lib\\re.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_deletes(s: str):\n",
    "    deletes = re.finditer(\"#DELETE#([0-9]+)#\", s)\n",
    "    if deletes:\n",
    "        s1 =  ''\n",
    "        prev_idx = 0\n",
    "        for match in sorted(list(deletes), key=lambda x: x.span()[0]):\n",
    "            s1 += s[prev_idx:match.span()[0]]\n",
    "            prev_idx = match.span()[1] + int(match.group(1))\n",
    "        s1 += s[prev_idx:len(s)]\n",
    "        return s1\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def sent_tokenize_function(s: str):\n",
    "    s = remove_deletes(s)\n",
    "    sents = []\n",
    "    sent = ''\n",
    "    escaped = False\n",
    "    capital = False\n",
    "    prev_sym = ''\n",
    "    for sym in s:\n",
    "        sent += sym\n",
    "        if sym == '<' and prev_sym == '<':\n",
    "            escaped = True\n",
    "        elif sym == '>' and prev_sym == '>':\n",
    "            escaped = False\n",
    "        elif sym in '?!.':\n",
    "            if not (escaped or capital):\n",
    "                sents.append(sent.strip())\n",
    "                sent = ''\n",
    "            else:\n",
    "                pass\n",
    "        elif capital:\n",
    "            capital = False\n",
    "        elif sym.isupper():\n",
    "            capital = True\n",
    "        prev_sym = sym\n",
    "    sents.append(sent.strip())\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = [\n",
    "    (\n",
    "        name, sent_tokenize_function(text.decode(\"utf-8\")), meta\n",
    "    ) for name, text, meta in processed_texts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('processed_texts/15753.txt',\n",
       " ['<<Nowadays,**T1**punct**None**8**Nowadays>> we can not imagine any competitive product without <<PR-compain**T2**Articles**None**14**the PR-campain>>.',\n",
       "  'But some businesses are trying not to show dangerous features of their products which can <<have a**T4**vocab**None**5**cause>> dramatic effect on customers and lead to health problems.',\n",
       "  'In my point of view, it depends on the kind of <<product**T5**Articles**None**11**the product>> and it does not have to be <<immediately**T6**Spelling**None**10**immediatly>> banned and not advertised.',\n",
       "  'There are a great number of different goods that can lead to diseases and it is impossible  to live without <<them nowadays**T8**vocab**None**4**them>>.',\n",
       "  'To start with, different <<kinds**T9**Noun_number**None**4**kind>> of vehicles produce <<a variety**T10**Articles**None**11**the variety>> of gases that lead to death but we can not travel without them.',\n",
       "  'For example, it is evident that cars produce gas which damages the ozone layer.',\n",
       "  'Secondly, drugs and medicines are the best way to cure <<an**T11**gram**None**4**from>> illness nevertheless it has a lot of side effects.',\n",
       "  \"Finally, a lot of cosmetics can cause <<damage**T13**Articles**None**8**a damage>> <<to**T14**gram**None**3**for>> someone's health if <<they are**T15**disc**None**5**it is>> not suitable.\",\n",
       "  'Other people suggest that we have to ban <<advertising**T16**vocab**None**12**advertisment>> companies that promote goods that are harmful to prevent the encouragement of people to buy them.',\n",
       "  'First, they say we should decrease the amount of <<advertising**T17**vocab**None**12**advertisment>> of such products in order to make them less popular and decrease <<their**T18**gram**None**3**the>> production.',\n",
       "  'Finally, the promotion of harmful products is immoral.',\n",
       "  'For example, <<the goodwill**T19**Articles**None**8**goodwill>> of <<a company**T20**Articles**None**11**the company>> can <<become**T21**gram**None**6**became>> much <<weaker**T22**spell**None**7**chaeper>> when people <<understand**T23**Spelling**None**10**understant>> that the business <<supports**T24**comp**None**7**support>> dangerous goods.',\n",
       "  'To sum up, there <<are**T25**comp**None**2**is>> two points of view on this issue.',\n",
       "  'Some people think we can not live without <<such**T26**Spelling**None**4**sich>> products and <<advertising,**T27**punct**None**12**advertisment>> but some think we have to ban it.',\n",
       "  'I support the first <<group**T28**Spelling**None**6**groupe>>.',\n",
       "  ''],\n",
       " {'text_type': None,\n",
       "  'ielts': 'TRUE',\n",
       "  'CEFR_level': None,\n",
       "  'task_id': 'O18',\n",
       "  'ann_checked': 0,\n",
       "  'work_type': 'exam',\n",
       "  'filename': '2020_MLa_2297_2',\n",
       "  'folder': 'downloaded_2022_05_03_13_27_13286380/exam/Exam2020/Task_3_Essays_1897_2839'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет:\n",
    "\n",
    "Слово - Папка - Filename - Предложение - Предложение с маской на месте слова - CEFR Level - Употреблено ли вместо этого слово какое-то другое ошибочно (ошибки типа lex_item_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_variants = pd.read_csv(\n",
    "    \"dataset_lexics_final3.csv\",\n",
    "    sep=';',\n",
    "    index_col=\"Unnamed: 0\"\n",
    ")\n",
    "dataset_variantas = dataset_variants.loc[dataset_variants[\"Delete\"]!=1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>target</th>\n",
       "      <th>variant</th>\n",
       "      <th>correction</th>\n",
       "      <th>masked_sent</th>\n",
       "      <th>variant_count</th>\n",
       "      <th>correction_count</th>\n",
       "      <th>error_type</th>\n",
       "      <th>target_true</th>\n",
       "      <th>Delete</th>\n",
       "      <th>File</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Revisited1</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>understandings</td>\n",
       "      <td>perceptions</td>\n",
       "      <td>To start with, happiness is a feeling of comf...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014_EZa_13_2</td>\n",
       "      <td>exam/Exam2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exam/Exam2014/2014_EZa_13_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>strictly</td>\n",
       "      <td>absolutely</td>\n",
       "      <td>I know that she was healthy and that her birt...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014_EZa_13_2</td>\n",
       "      <td>exam/Exam2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exam/Exam2014/2014_EZa_13_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>completely</td>\n",
       "      <td>absolutely</td>\n",
       "      <td>I know that she was healthy and that her birt...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014_EZa_13_2</td>\n",
       "      <td>exam/Exam2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exam/Exam2014/2014_EZa_13_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>definitely</td>\n",
       "      <td>absolutely</td>\n",
       "      <td>I know that she was healthy and that her birt...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014_EZa_13_2</td>\n",
       "      <td>exam/Exam2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exam/Exam2014/2014_EZa_13_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>needs</td>\n",
       "      <td>requires</td>\n",
       "      <td>It helps to use all resources more effectivel...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017_NMya_85_2</td>\n",
       "      <td>exam/Exam2017/NMya_1-108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exam/Exam2017/NMya_1-108/2017_NMya_85_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107289</th>\n",
       "      <td>167646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>appear</td>\n",
       "      <td>result</td>\n",
       "      <td>Comparing the EU and Latin America, the EU ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_ABl_20_1</td>\n",
       "      <td>exam/Exam2017/ABl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exam/Exam2017/ABl/2017_ABl_20_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107290</th>\n",
       "      <td>167646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>time</td>\n",
       "      <td>result</td>\n",
       "      <td>Comparing the EU and Latin America, the EU ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017_ABl_20_1</td>\n",
       "      <td>exam/Exam2017/ABl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exam/Exam2017/ABl/2017_ABl_20_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107597</th>\n",
       "      <td>167664.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>grow</td>\n",
       "      <td>raise</td>\n",
       "      <td>Secondly, knowing that they have a huge socia...</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020_MLa_2063_2</td>\n",
       "      <td>exam/Exam2020/Task_3_Essays_1897_2839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exam/Exam2020/Task_3_Essays_1897_2839/2020_MLa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107600</th>\n",
       "      <td>167664.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>improve</td>\n",
       "      <td>raise</td>\n",
       "      <td>Secondly, knowing that they have a huge socia...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020_MLa_2063_2</td>\n",
       "      <td>exam/Exam2020/Task_3_Essays_1897_2839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exam/Exam2020/Task_3_Essays_1897_2839/2020_MLa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107610</th>\n",
       "      <td>167664.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>force</td>\n",
       "      <td>raise</td>\n",
       "      <td>Secondly, knowing that they have a huge socia...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>lex_item_choice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020_MLa_2063_2</td>\n",
       "      <td>exam/Exam2020/Task_3_Essays_1897_2839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exam/Exam2020/Task_3_Essays_1897_2839/2020_MLa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12679 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sent_id  target         variant   correction  \\\n",
       "Unnamed: 0                                                  \n",
       "1167            88.0     1.0  understandings  perceptions   \n",
       "1173            93.0     1.0        strictly   absolutely   \n",
       "1174            93.0     0.0      completely   absolutely   \n",
       "1187            93.0     0.0      definitely   absolutely   \n",
       "2051           146.0     1.0           needs     requires   \n",
       "...              ...     ...             ...          ...   \n",
       "3107289     167646.0     0.0          appear       result   \n",
       "3107290     167646.0     0.0            time       result   \n",
       "3107597     167664.0     0.0            grow        raise   \n",
       "3107600     167664.0     0.0         improve        raise   \n",
       "3107610     167664.0     1.0           force        raise   \n",
       "\n",
       "                                                  masked_sent  variant_count  \\\n",
       "Unnamed: 0                                                                     \n",
       "1167         To start with, happiness is a feeling of comf...              1   \n",
       "1173         I know that she was healthy and that her birt...              2   \n",
       "1174         I know that she was healthy and that her birt...              2   \n",
       "1187         I know that she was healthy and that her birt...              1   \n",
       "2051         It helps to use all resources more effectivel...              2   \n",
       "...                                                       ...            ...   \n",
       "3107289      Comparing the EU and Latin America, the EU ha...              1   \n",
       "3107290      Comparing the EU and Latin America, the EU ha...              1   \n",
       "3107597      Secondly, knowing that they have a huge socia...              2   \n",
       "3107600      Secondly, knowing that they have a huge socia...              1   \n",
       "3107610      Secondly, knowing that they have a huge socia...              1   \n",
       "\n",
       "            correction_count       error_type  target_true  Delete  \\\n",
       "Unnamed: 0                                                           \n",
       "1167                       1  lex_item_choice          1.0     0.0   \n",
       "1173                       5  lex_item_choice          1.0     0.0   \n",
       "1174                       5  lex_item_choice          0.0     0.0   \n",
       "1187                       5  lex_item_choice          1.0     0.0   \n",
       "2051                       3  lex_item_choice          1.0     1.0   \n",
       "...                      ...              ...          ...     ...   \n",
       "3107289                    3  lex_item_choice          NaN     0.0   \n",
       "3107290                    3  lex_item_choice          NaN     0.0   \n",
       "3107597                   35  lex_item_choice          NaN     0.0   \n",
       "3107600                   35  lex_item_choice          NaN     0.0   \n",
       "3107610                   35  lex_item_choice          NaN     0.0   \n",
       "\n",
       "                       File                                 Folder  \\\n",
       "Unnamed: 0                                                           \n",
       "1167          2014_EZa_13_2                          exam/Exam2014   \n",
       "1173          2014_EZa_13_2                          exam/Exam2014   \n",
       "1174          2014_EZa_13_2                          exam/Exam2014   \n",
       "1187          2014_EZa_13_2                          exam/Exam2014   \n",
       "2051         2017_NMya_85_2               exam/Exam2017/NMya_1-108   \n",
       "...                     ...                                    ...   \n",
       "3107289       2017_ABl_20_1                      exam/Exam2017/ABl   \n",
       "3107290       2017_ABl_20_1                      exam/Exam2017/ABl   \n",
       "3107597     2020_MLa_2063_2  exam/Exam2020/Task_3_Essays_1897_2839   \n",
       "3107600     2020_MLa_2063_2  exam/Exam2020/Task_3_Essays_1897_2839   \n",
       "3107610     2020_MLa_2063_2  exam/Exam2020/Task_3_Essays_1897_2839   \n",
       "\n",
       "            Revisited1                                           Filename  \n",
       "Unnamed: 0                                                                 \n",
       "1167               1.0                        exam/Exam2014/2014_EZa_13_2  \n",
       "1173               1.0                        exam/Exam2014/2014_EZa_13_2  \n",
       "1174               1.0                        exam/Exam2014/2014_EZa_13_2  \n",
       "1187               1.0                        exam/Exam2014/2014_EZa_13_2  \n",
       "2051               1.0            exam/Exam2017/NMya_1-108/2017_NMya_85_2  \n",
       "...                ...                                                ...  \n",
       "3107289            NaN                    exam/Exam2017/ABl/2017_ABl_20_1  \n",
       "3107290            NaN                    exam/Exam2017/ABl/2017_ABl_20_1  \n",
       "3107597            NaN  exam/Exam2020/Task_3_Essays_1897_2839/2020_MLa...  \n",
       "3107600            NaN  exam/Exam2020/Task_3_Essays_1897_2839/2020_MLa...  \n",
       "3107610            NaN  exam/Exam2020/Task_3_Essays_1897_2839/2020_MLa...  \n",
       "\n",
       "[12679 rows x 14 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dataset_variants[\"correction\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_out = []\n",
    "processed_texts = [\n",
    "    (text_id, list(enumerate(text)), meta) for text_id, text, meta in processed_texts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19984\\2293805388.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for word in tqdm_notebook(words, total=len(words)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91a8da6a79d466081feee93a32a3a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word in tqdm_notebook(words, total=len(words)):\n",
    "    for text_id, text, meta in processed_texts:\n",
    "        for sent_id, sent in text:\n",
    "            pattern = re.compile(\n",
    "                f\"<<{word}\\*\\*(T[0-9]+)\\*\\*lex_item_choice.*?>>\",\n",
    "                re.DOTALL\n",
    "            )\n",
    "            match = re.search(pattern, sent)\n",
    "            if match:\n",
    "                dataset_out.append({\n",
    "                    \"word\": word,\n",
    "                    \"index\": match.group(1),\n",
    "                    \"folder\": meta.get(\"folder\"),\n",
    "                    \"fielname\": meta.get(\"filename\"),\n",
    "                    \"sent\": sent,\n",
    "                    \"sent_id\": sent_id,\n",
    "                    \"CEFR_level\": meta.get(\"CEFR_level\"),\n",
    "                    \"target\": 1\n",
    "                })\n",
    "            else:\n",
    "                sent_clear = re.sub(\n",
    "                    \"<<.*?>>\",\n",
    "                    '',\n",
    "                    sent\n",
    "                )\n",
    "                match = re.search(f\"(?<!\\w){word}(?!\\w)\", sent_clear)\n",
    "                if match:\n",
    "                    dataset_out.append({\n",
    "                    \"word\": word,\n",
    "                    \"span_clear\": match.span(),\n",
    "                    \"folder\": meta.get(\"folder\"),\n",
    "                    \"fielname\": meta.get(\"filename\"),\n",
    "                    \"sent\": sent,\n",
    "                    \"sent_id\": sent_id,\n",
    "                    \"CEFR_level\": meta.get(\"CEFR_level\"),\n",
    "                    \"target\": 0\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(dataset_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1034829\n",
       "1       6120\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.994121\n",
       "1    0.005879\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[\"target\"].value_counts()/len(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>index</th>\n",
       "      <th>folder</th>\n",
       "      <th>fielname</th>\n",
       "      <th>sent</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>CEFR_level</th>\n",
       "      <th>target</th>\n",
       "      <th>span_clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perceptions</td>\n",
       "      <td>T4</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_EZa_13_2</td>\n",
       "      <td>&lt;&lt;However,**T3**Punctuation**None**7**However&gt;...</td>\n",
       "      <td>3</td>\n",
       "      <td>B2+</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "      <td>2020_MLa_5542_2</td>\n",
       "      <td>First and foremost, the ideas of &lt;&lt;capitalism,...</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>(139, 149)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_DZu_31_2</td>\n",
       "      <td>Moreover, I can say with confidence that durin...</td>\n",
       "      <td>9</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(78, 88)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_DZu_31_2</td>\n",
       "      <td>I am absolutely sure that people we meet in ou...</td>\n",
       "      <td>13</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(5, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "      <td>2020_MLa_5234_2</td>\n",
       "      <td>On the other hand, pharmaceutical companies, d...</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>(139, 149)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040944</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2016_EKu_125_2</td>\n",
       "      <td>When people hear about a cruel crime, everybod...</td>\n",
       "      <td>0</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(25, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040945</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2016_EKu_125_2</td>\n",
       "      <td>As for me, I find long prison sentences too cr...</td>\n",
       "      <td>10</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(44, 49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040946</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Exam...</td>\n",
       "      <td>2020_MLa_5833_2</td>\n",
       "      <td>That is why, &lt;&lt;nowadays,**T28**punct**None**7*...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>(50, 55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040947</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2017_EGe_83_2</td>\n",
       "      <td>Moreover, children &lt;&lt;play**T22**lex_item_choic...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>(55, 60)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040948</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2017_VSa_73_2</td>\n",
       "      <td>I think that this kind of punishment for &lt;&lt;fir...</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>(68, 73)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040949 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word index                                             folder  \\\n",
       "0        perceptions    T4  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1         absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Exam...   \n",
       "2         absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "3         absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "4         absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Exam...   \n",
       "...              ...   ...                                                ...   \n",
       "1040944        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040945        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040946        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Exam...   \n",
       "1040947        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040948        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "\n",
       "                fielname                                               sent  \\\n",
       "0          2014_EZa_13_2  <<However,**T3**Punctuation**None**7**However>...   \n",
       "1        2020_MLa_5542_2  First and foremost, the ideas of <<capitalism,...   \n",
       "2          2014_DZu_31_2  Moreover, I can say with confidence that durin...   \n",
       "3          2014_DZu_31_2  I am absolutely sure that people we meet in ou...   \n",
       "4        2020_MLa_5234_2  On the other hand, pharmaceutical companies, d...   \n",
       "...                  ...                                                ...   \n",
       "1040944   2016_EKu_125_2  When people hear about a cruel crime, everybod...   \n",
       "1040945   2016_EKu_125_2  As for me, I find long prison sentences too cr...   \n",
       "1040946  2020_MLa_5833_2  That is why, <<nowadays,**T28**punct**None**7*...   \n",
       "1040947    2017_EGe_83_2  Moreover, children <<play**T22**lex_item_choic...   \n",
       "1040948    2017_VSa_73_2  I think that this kind of punishment for <<fir...   \n",
       "\n",
       "         sent_id CEFR_level  target  span_clear  \n",
       "0              3        B2+       1         NaN  \n",
       "1              4                  0  (139, 149)  \n",
       "2              9        B1+       0    (78, 88)  \n",
       "3             13        B1+       0     (5, 15)  \n",
       "4              6                  0  (139, 149)  \n",
       "...          ...        ...     ...         ...  \n",
       "1040944        0        B1+       0    (25, 30)  \n",
       "1040945       10        B1+       0    (44, 49)  \n",
       "1040946        8                  0    (50, 55)  \n",
       "1040947        8                  0    (55, 60)  \n",
       "1040948       11                  0    (68, 73)  \n",
       "\n",
       "[1040949 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_out[~df_out[\"CEFR_level\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       460341\n",
       "B1+     87963\n",
       "B2+     59654\n",
       "B1      33785\n",
       "C1      29259\n",
       "B2      25837\n",
       "C1+     10997\n",
       "B1-      5878\n",
       "A2        335\n",
       "Name: CEFR_level, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[\"CEFR_level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_out.loc[df_out[\"CEFR_level\"]!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.984384\n",
       "1    0.015616\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[\"target\"].value_counts()/len(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B1+    0.346710\n",
       "B2+    0.235129\n",
       "B1     0.133165\n",
       "C1     0.115325\n",
       "B2     0.101838\n",
       "C1+    0.043345\n",
       "B1-    0.023168\n",
       "A2     0.001320\n",
       "Name: CEFR_level, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[\"CEFR_level\"].value_counts()/len(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_out.loc[\n",
    "    df_out[\"CEFR_level\"].apply(\n",
    "        lambda x: x in [\"B1\",\"B1+\",\"B2\",\"B2+\",\"C1\",\"C1+\"]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>index</th>\n",
       "      <th>folder</th>\n",
       "      <th>fielname</th>\n",
       "      <th>sent</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>CEFR_level</th>\n",
       "      <th>target</th>\n",
       "      <th>span_clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perceptions</td>\n",
       "      <td>T4</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_EZa_13_2</td>\n",
       "      <td>&lt;&lt;However,**T3**Punctuation**None**7**However&gt;...</td>\n",
       "      <td>3</td>\n",
       "      <td>B2+</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_DZu_31_2</td>\n",
       "      <td>Moreover, I can say with confidence that durin...</td>\n",
       "      <td>9</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(78, 88)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_DZu_31_2</td>\n",
       "      <td>I am absolutely sure that people we meet in ou...</td>\n",
       "      <td>13</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(5, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2017_MPa_62_2</td>\n",
       "      <td>To conclude, I firmly believe that there are c...</td>\n",
       "      <td>11</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>(76, 86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_ASt_35_2</td>\n",
       "      <td>Summing up, I  absolutely do not agree that &lt;&lt;...</td>\n",
       "      <td>14</td>\n",
       "      <td>B2+</td>\n",
       "      <td>0</td>\n",
       "      <td>(15, 25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040939</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2017_KTR_1_2</td>\n",
       "      <td>The second opinion is that &lt;&lt;cheating**T29**Pa...</td>\n",
       "      <td>6</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "      <td>(54, 59)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040940</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2017_EGe_25_2</td>\n",
       "      <td>The world is a cruel place and it have never h...</td>\n",
       "      <td>3</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>(15, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040942</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2016_JSl_193_2</td>\n",
       "      <td>In conclusion, I'd like to say that law breake...</td>\n",
       "      <td>15</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>(78, 83)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040944</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2016_EKu_125_2</td>\n",
       "      <td>When people hear about a cruel crime, everybod...</td>\n",
       "      <td>0</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(25, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040945</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2016_EKu_125_2</td>\n",
       "      <td>As for me, I find long prison sentences too cr...</td>\n",
       "      <td>10</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(44, 49)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247495 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word index                                             folder  \\\n",
       "0        perceptions    T4  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "2         absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "3         absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "11        absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "12        absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "...              ...   ...                                                ...   \n",
       "1040939        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040940        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040942        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040944        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040945        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "\n",
       "               fielname                                               sent  \\\n",
       "0         2014_EZa_13_2  <<However,**T3**Punctuation**None**7**However>...   \n",
       "2         2014_DZu_31_2  Moreover, I can say with confidence that durin...   \n",
       "3         2014_DZu_31_2  I am absolutely sure that people we meet in ou...   \n",
       "11        2017_MPa_62_2  To conclude, I firmly believe that there are c...   \n",
       "12        2014_ASt_35_2  Summing up, I  absolutely do not agree that <<...   \n",
       "...                 ...                                                ...   \n",
       "1040939    2017_KTR_1_2  The second opinion is that <<cheating**T29**Pa...   \n",
       "1040940   2017_EGe_25_2  The world is a cruel place and it have never h...   \n",
       "1040942  2016_JSl_193_2  In conclusion, I'd like to say that law breake...   \n",
       "1040944  2016_EKu_125_2  When people hear about a cruel crime, everybod...   \n",
       "1040945  2016_EKu_125_2  As for me, I find long prison sentences too cr...   \n",
       "\n",
       "         sent_id CEFR_level  target span_clear  \n",
       "0              3        B2+       1        NaN  \n",
       "2              9        B1+       0   (78, 88)  \n",
       "3             13        B1+       0    (5, 15)  \n",
       "11            11         C1       0   (76, 86)  \n",
       "12            14        B2+       0   (15, 25)  \n",
       "...          ...        ...     ...        ...  \n",
       "1040939        6         B2       0   (54, 59)  \n",
       "1040940        3         B1       0   (15, 20)  \n",
       "1040942       15         B1       0   (78, 83)  \n",
       "1040944        0        B1+       0   (25, 30)  \n",
       "1040945       10        B1+       0   (44, 49)  \n",
       "\n",
       "[247495 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[\"sent_clear\"] = df_out[\"sent\"].apply(\n",
    "    lambda x: re.sub(\n",
    "        \"<<(.*?)\\*\\*.*?\\*\\*.*?\\*\\*.*?\\*\\*.*?\\*\\*.*?>>\",\n",
    "        r\"\\1\",\n",
    "        x\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format(\n",
    "    \"gensim_models/skipgram_wikipedia_no_lemma/model.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[\"word_vector\"] = df_out[\"word\"].apply(\n",
    "    lambda x: word2vec[x]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>index</th>\n",
       "      <th>folder</th>\n",
       "      <th>fielname</th>\n",
       "      <th>sent</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>CEFR_level</th>\n",
       "      <th>target</th>\n",
       "      <th>span_clear</th>\n",
       "      <th>sent_clear</th>\n",
       "      <th>word_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perceptions</td>\n",
       "      <td>T4</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_EZa_13_2</td>\n",
       "      <td>&lt;&lt;However,**T3**Punctuation**None**7**However&gt;...</td>\n",
       "      <td>3</td>\n",
       "      <td>B2+</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>However, all people are different and they hav...</td>\n",
       "      <td>[0.3426203, 0.22680311, 0.14678335, 0.01468511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_DZu_31_2</td>\n",
       "      <td>Moreover, I can say with confidence that durin...</td>\n",
       "      <td>9</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(78, 88)</td>\n",
       "      <td>Moreover, I can say with confidence that durin...</td>\n",
       "      <td>[-0.19043966, 0.28531945, -0.024855996, -0.191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_DZu_31_2</td>\n",
       "      <td>I am absolutely sure that people we meet in ou...</td>\n",
       "      <td>13</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(5, 15)</td>\n",
       "      <td>I am absolutely sure that people we meet in ou...</td>\n",
       "      <td>[-0.19043966, 0.28531945, -0.024855996, -0.191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2017_MPa_62_2</td>\n",
       "      <td>To conclude, I firmly believe that there are c...</td>\n",
       "      <td>11</td>\n",
       "      <td>C1</td>\n",
       "      <td>0</td>\n",
       "      <td>(76, 86)</td>\n",
       "      <td>To conclude, I firmly believe that there are c...</td>\n",
       "      <td>[-0.19043966, 0.28531945, -0.024855996, -0.191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2014_ASt_35_2</td>\n",
       "      <td>Summing up, I  absolutely do not agree that &lt;&lt;...</td>\n",
       "      <td>14</td>\n",
       "      <td>B2+</td>\n",
       "      <td>0</td>\n",
       "      <td>(15, 25)</td>\n",
       "      <td>Summing up, I  absolutely do not agree that ou...</td>\n",
       "      <td>[-0.19043966, 0.28531945, -0.024855996, -0.191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040939</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2017_KTR_1_2</td>\n",
       "      <td>The second opinion is that &lt;&lt;cheating**T29**Pa...</td>\n",
       "      <td>6</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "      <td>(54, 59)</td>\n",
       "      <td>The second opinion is that cheating in profess...</td>\n",
       "      <td>[0.19856142, 0.5089491, -0.1001941, 0.40547368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040940</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2017_EGe_25_2</td>\n",
       "      <td>The world is a cruel place and it have never h...</td>\n",
       "      <td>3</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>The world is a cruel place and it have never h...</td>\n",
       "      <td>[0.19856142, 0.5089491, -0.1001941, 0.40547368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040942</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2016_JSl_193_2</td>\n",
       "      <td>In conclusion, I'd like to say that law breake...</td>\n",
       "      <td>15</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>(78, 83)</td>\n",
       "      <td>In conclusion, I'd like to say that law breake...</td>\n",
       "      <td>[0.19856142, 0.5089491, -0.1001941, 0.40547368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040944</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2016_EKu_125_2</td>\n",
       "      <td>When people hear about a cruel crime, everybod...</td>\n",
       "      <td>0</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(25, 30)</td>\n",
       "      <td>When people hear about a cruel crime, everybod...</td>\n",
       "      <td>[0.19856142, 0.5089491, -0.1001941, 0.40547368...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040945</th>\n",
       "      <td>cruel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downloaded_2022_05_03_13_27_13286380/exam/Old_...</td>\n",
       "      <td>2016_EKu_125_2</td>\n",
       "      <td>As for me, I find long prison sentences too cr...</td>\n",
       "      <td>10</td>\n",
       "      <td>B1+</td>\n",
       "      <td>0</td>\n",
       "      <td>(44, 49)</td>\n",
       "      <td>As for me, I find long prison sentences too cr...</td>\n",
       "      <td>[0.19856142, 0.5089491, -0.1001941, 0.40547368...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247495 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word index                                             folder  \\\n",
       "0        perceptions    T4  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "2         absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "3         absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "11        absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "12        absolutely   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "...              ...   ...                                                ...   \n",
       "1040939        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040940        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040942        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040944        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "1040945        cruel   NaN  downloaded_2022_05_03_13_27_13286380/exam/Old_...   \n",
       "\n",
       "               fielname                                               sent  \\\n",
       "0         2014_EZa_13_2  <<However,**T3**Punctuation**None**7**However>...   \n",
       "2         2014_DZu_31_2  Moreover, I can say with confidence that durin...   \n",
       "3         2014_DZu_31_2  I am absolutely sure that people we meet in ou...   \n",
       "11        2017_MPa_62_2  To conclude, I firmly believe that there are c...   \n",
       "12        2014_ASt_35_2  Summing up, I  absolutely do not agree that <<...   \n",
       "...                 ...                                                ...   \n",
       "1040939    2017_KTR_1_2  The second opinion is that <<cheating**T29**Pa...   \n",
       "1040940   2017_EGe_25_2  The world is a cruel place and it have never h...   \n",
       "1040942  2016_JSl_193_2  In conclusion, I'd like to say that law breake...   \n",
       "1040944  2016_EKu_125_2  When people hear about a cruel crime, everybod...   \n",
       "1040945  2016_EKu_125_2  As for me, I find long prison sentences too cr...   \n",
       "\n",
       "         sent_id CEFR_level  target span_clear  \\\n",
       "0              3        B2+       1        NaN   \n",
       "2              9        B1+       0   (78, 88)   \n",
       "3             13        B1+       0    (5, 15)   \n",
       "11            11         C1       0   (76, 86)   \n",
       "12            14        B2+       0   (15, 25)   \n",
       "...          ...        ...     ...        ...   \n",
       "1040939        6         B2       0   (54, 59)   \n",
       "1040940        3         B1       0   (15, 20)   \n",
       "1040942       15         B1       0   (78, 83)   \n",
       "1040944        0        B1+       0   (25, 30)   \n",
       "1040945       10        B1+       0   (44, 49)   \n",
       "\n",
       "                                                sent_clear  \\\n",
       "0        However, all people are different and they hav...   \n",
       "2        Moreover, I can say with confidence that durin...   \n",
       "3        I am absolutely sure that people we meet in ou...   \n",
       "11       To conclude, I firmly believe that there are c...   \n",
       "12       Summing up, I  absolutely do not agree that ou...   \n",
       "...                                                    ...   \n",
       "1040939  The second opinion is that cheating in profess...   \n",
       "1040940  The world is a cruel place and it have never h...   \n",
       "1040942  In conclusion, I'd like to say that law breake...   \n",
       "1040944  When people hear about a cruel crime, everybod...   \n",
       "1040945  As for me, I find long prison sentences too cr...   \n",
       "\n",
       "                                               word_vector  \n",
       "0        [0.3426203, 0.22680311, 0.14678335, 0.01468511...  \n",
       "2        [-0.19043966, 0.28531945, -0.024855996, -0.191...  \n",
       "3        [-0.19043966, 0.28531945, -0.024855996, -0.191...  \n",
       "11       [-0.19043966, 0.28531945, -0.024855996, -0.191...  \n",
       "12       [-0.19043966, 0.28531945, -0.024855996, -0.191...  \n",
       "...                                                    ...  \n",
       "1040939  [0.19856142, 0.5089491, -0.1001941, 0.40547368...  \n",
       "1040940  [0.19856142, 0.5089491, -0.1001941, 0.40547368...  \n",
       "1040942  [0.19856142, 0.5089491, -0.1001941, 0.40547368...  \n",
       "1040944  [0.19856142, 0.5089491, -0.1001941, 0.40547368...  \n",
       "1040945  [0.19856142, 0.5089491, -0.1001941, 0.40547368...  \n",
       "\n",
       "[247495 rows x 11 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19984\\3226173829.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for word in tqdm_notebook(df_out[\"word\"].unique(), total=len(df_out[\"word\"].unique())):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe885d0dd17e44a897991452b0649522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats = []\n",
    "\n",
    "for word in tqdm_notebook(df_out[\"word\"].unique(), total=len(df_out[\"word\"].unique())):\n",
    "    df_stats.append({\n",
    "        \"word\": word,\n",
    "        \"0\": df_out.loc[df_out[\"word\"]==word][\"target\"].value_counts().get(0),\n",
    "        \"1\": df_out.loc[df_out[\"word\"]==word][\"target\"].value_counts().get(1),\n",
    "        \"count\": len(df_out.loc[df_out[\"word\"]==word][\"target\"])\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(df_stats)\n",
    "\n",
    "df_stats[\"ratio\"] = df_stats[\"1\"]/df_stats[\"count\"]\n",
    "\n",
    "good_words = df_stats[df_stats[\"ratio\"] > 0.05][\"word\"].tolist()\n",
    "\n",
    "df_out = df_out.loc[\n",
    "    df_out[\"word\"].apply(lambda x: x in good_words)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word', 'index', 'folder', 'fielname', 'sent', 'sent_id', 'CEFR_level',\n",
       "       'target', 'span_clear', 'sent_clear', 'word_vector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19984\\1220360630.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out[\"sent_uid\"] = df_out.apply(\n"
     ]
    }
   ],
   "source": [
    "df_out[\"sent_uid\"] = df_out.apply(\n",
    "    lambda x: f\"{x['folder']}/{x['fielname']}/{sent_id}\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_id_train, sent_id_test = train_test_split(\n",
    "    df_out.sent_uid.unique(),\n",
    "    random_state=1138,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = df_out.loc[df_out[\"sent_uid\"].isin(sent_id_train)].index\n",
    "index_test = df_out.loc[df_out[\"sent_uid\"].isin(sent_id_test)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13365"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3329"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "843"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_id_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer().fit(df_out.loc[index_train][\"sent_clear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16694"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.913142\n",
       "1    0.086858\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out[\"target\"].value_counts()/len(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf.transform(df_out.loc[index_train][\"sent_clear\"]).toarray()\n",
    "tfidf_test = tfidf.transform(df_out.loc[index_test][\"sent_clear\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(\"df_out_error_prediction_value_counts.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train = np.array(df_out.loc[index_train][\"word_vector\"].tolist())\n",
    "w2v_test = np.array(df_out.loc[index_test][\"word_vector\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder().fit(df_out[[\"CEFR_level\"]])\n",
    "cefr_train  = enc.transform(df_out.loc[index_train][[\"CEFR_level\"]]).toarray()\n",
    "cefr_test = enc.transform(df_out.loc[index_test][[\"CEFR_level\"]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13365, 300), (13365, 6865), (13365, 6))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_train.shape, tfidf_train.shape, cefr_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack([w2v_train, tfidf_train, cefr_train])\n",
    "X_test = np.hstack([w2v_test, tfidf_test, cefr_test])\n",
    "y_train = df_out.loc[index_train][\"target\"]\n",
    "y_test = df_out.loc[index_test][\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13365, 7171), (3329, 7171))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12206\n",
       "1     1159\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3038\n",
       "1     291\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telegram.ext import Updater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19984\\2460129039.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for name, clf in tqdm_notebook(zip(names, classifiers), total=len(names)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b6b146d779460fb17e460d8cb183d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\MasterThesis\\master_thesis_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors=1),\n",
    "    KNeighborsClassifier(n_neighbors=2),\n",
    "    KNeighborsClassifier(n_neighbors=3),\n",
    "    KNeighborsClassifier(n_neighbors=4),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    LinearSVC(random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    LogisticRegression(random_state=42),\n",
    "    RidgeClassifier(random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    GaussianNB()\n",
    "]\n",
    "\n",
    "names = [type(clf).__name__ for clf in classifiers]\n",
    "\n",
    "result_df = []\n",
    "\n",
    "for name, clf in tqdm_notebook(zip(names, classifiers), total=len(names)):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = np.round(clf.predict(X_train))\n",
    "    y_test_pred = np.round(clf.predict(X_test))\n",
    "\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "    result_df.append({\n",
    "        \"name\": name,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"train_f1\": train_f1,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"test_precision\": test_precision,\n",
    "        \"train_precision\": train_precision,\n",
    "        \"test_recall\": test_recall,\n",
    "        \"train_recall\": train_recall\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.199081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223368</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.420981</td>\n",
       "      <td>0.903575</td>\n",
       "      <td>0.936401</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.266609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.491633</td>\n",
       "      <td>0.890057</td>\n",
       "      <td>0.934082</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.742160</td>\n",
       "      <td>0.123711</td>\n",
       "      <td>0.367558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>0.226048</td>\n",
       "      <td>0.907179</td>\n",
       "      <td>0.922634</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.130285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.280193</td>\n",
       "      <td>0.903575</td>\n",
       "      <td>0.921960</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>0.175151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.361851</td>\n",
       "      <td>0.908381</td>\n",
       "      <td>0.931912</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.222606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.192496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.183230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202749</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.075970</td>\n",
       "      <td>0.911685</td>\n",
       "      <td>0.916274</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.017182</td>\n",
       "      <td>0.039689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.160757</td>\n",
       "      <td>0.910784</td>\n",
       "      <td>0.920314</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.088007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.152439</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>0.916491</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085911</td>\n",
       "      <td>0.998274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.058872</td>\n",
       "      <td>0.910183</td>\n",
       "      <td>0.913880</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.031061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.082713</td>\n",
       "      <td>0.912286</td>\n",
       "      <td>0.917022</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.043141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.154011</td>\n",
       "      <td>0.304080</td>\n",
       "      <td>0.524782</td>\n",
       "      <td>0.603068</td>\n",
       "      <td>0.091197</td>\n",
       "      <td>0.179301</td>\n",
       "      <td>0.494845</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name   test_f1  train_f1  test_acc  train_acc  \\\n",
       "0         KNeighborsClassifier  0.199081  1.000000  0.842896   1.000000   \n",
       "1         KNeighborsClassifier  0.130081  0.420981  0.903575   0.936401   \n",
       "2         KNeighborsClassifier  0.164384  0.491633  0.890057   0.934082   \n",
       "3         KNeighborsClassifier  0.104348  0.226048  0.907179   0.922634   \n",
       "4         KNeighborsClassifier  0.115702  0.280193  0.903575   0.921960   \n",
       "5                    LinearSVC  0.089552  0.361851  0.908381   0.931912   \n",
       "6       DecisionTreeClassifier  0.192496  1.000000  0.851307   1.000000   \n",
       "7           LogisticRegression  0.032895  0.075970  0.911685   0.916274   \n",
       "8              RidgeClassifier  0.026230  0.160757  0.910784   0.920314   \n",
       "9       RandomForestClassifier  0.152439  0.999136  0.916491   0.999850   \n",
       "10          AdaBoostClassifier  0.019672  0.058872  0.910183   0.913880   \n",
       "11  GradientBoostingClassifier  0.039474  0.082713  0.912286   0.917022   \n",
       "12                  GaussianNB  0.154011  0.304080  0.524782   0.603068   \n",
       "\n",
       "    test_precision  train_precision  test_recall  train_recall  \n",
       "0         0.179558         1.000000     0.223368      1.000000  \n",
       "1         0.307692         1.000000     0.082474      0.266609  \n",
       "2         0.244898         0.742160     0.123711      0.367558  \n",
       "3         0.333333         0.853107     0.061856      0.130285  \n",
       "4         0.291667         0.700000     0.072165      0.175151  \n",
       "5         0.340909         0.966292     0.051546      0.222606  \n",
       "6         0.183230         1.000000     0.202749      1.000000  \n",
       "7         0.384615         0.884615     0.017182      0.039689  \n",
       "8         0.285714         0.927273     0.013746      0.088007  \n",
       "9         0.675676         1.000000     0.085911      0.998274  \n",
       "10        0.214286         0.562500     0.010309      0.031061  \n",
       "11        0.461538         1.000000     0.020619      0.043141  \n",
       "12        0.091197         0.179301     0.494845      1.000000  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result_df)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.912586\n",
       "1    0.087414\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.913281\n",
       "1    0.086719\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts() / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_out) == len(y_train) + len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf = DecisionTreeClassifier(random_state=42)\n",
    "best_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.Series({\n",
    "    i: best_clf.feature_importances_[i] for i in range(X_train.shape[1])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1489    0.000156\n",
       "3838    0.000157\n",
       "39      0.000157\n",
       "4266    0.000187\n",
       "3363    0.000187\n",
       "          ...   \n",
       "969     0.006403\n",
       "5614    0.007431\n",
       "156     0.010923\n",
       "3486    0.011788\n",
       "6462    0.012896\n",
       "Length: 851, dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[weights!=0.0].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {val:key for key,val in tfidf.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'understandably'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[6430]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_lens = pd.Series([len(word_tokenize(sent)) for sent in processed_sents])\n",
    "processed_counts = pd.Series([sent.count(\"<<\") for sent in processed_sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    231029.000000\n",
       "mean         48.529825\n",
       "std          34.628109\n",
       "min           1.000000\n",
       "25%          22.000000\n",
       "50%          40.000000\n",
       "75%          65.000000\n",
       "max         461.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_lens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    231029.000000\n",
       "mean          1.354644\n",
       "std           1.520121\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          19.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_excel(\n",
    "    \"TableI.xlsx\",\n",
    "    float_format=\"%.4f\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87a99aaab5997bb5662bde23a5190ed0ae9cf649d41a5ca6982601565cb11a4c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('master_thesis_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
